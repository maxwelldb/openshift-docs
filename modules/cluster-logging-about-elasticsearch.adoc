// Module included in the following assemblies:
//
// * logging/cluster-logging.adoc

[id="cluster-logging-about-elasticsearch_{context}"]
= About the logstore 

{product-title} uses link:https://www.elastic.co/products/elasticsearch[Elasticsearch (ES)] to organize the log data from Fluentd into datastores, or _indices_. 

Elasticsearch subdivides each index into multiple pieces called _shards_, which it spreads across a set of Elasticsearch nodes in an Elasticsearch cluster.
You can configure Elasticsearch to make copies of the shards, called _replicas_. Elasticsearch also spreads these replicas across
the Elasticsearch nodes. The *ClusterLogging* Custom Resource (CR) allows you to specify the replication policy to provide data redundancy and resilience to failure. You can also define how long indices should be retained using a retention policy in the Cluster Logging CR.

[NOTE]
====
The number of primary shards for the index templates is equal to the number of Elasticsearch data nodes.
====

The Cluster Logging Operator and companion Elasticsearch Operator ensure that each Elasticsearch node is deployed using a unique Deployment that includes its own storage volume.
You can use the Cluster Logging Custom Resource (CR) to increase the number of Elasticsearch nodes.
Refer to
link:https://www.elastic.co/guide/en/elasticsearch/guide/current/hardware.html[Elastic's
documentation] for considerations involved in choosing storage and
network location as directed below.

[NOTE]
====
A highly-available Elasticsearch environment requires at least three Elasticsearch nodes,
each on a different host.
====

Role-based access control (RBAC) applied on the Elasticsearch indices enables the controlled access of the logs to the developers. Access to the indices is restricted based on the permissions of the user in the specific project.

For more information, see https://www.elastic.co/products/elasticsearch[Elasticsearch (ES)].
